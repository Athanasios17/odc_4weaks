{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b11ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|gender| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TitanicAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"hdfs://namenode:9000/titanic_lab/titanic.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f8606b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|female|  217|\n",
      "|  male|  470|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Cabin.isNull()).groupBy(\"gender\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4704bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         avg(age)|\n",
      "+-----------------+\n",
      "|29.69911764705882|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "df.select(avg(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b1a45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_age=df.select(avg(\"age\")).first()[0]\n",
    "df=df.na.fill({\"age\":avg_age})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095d915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").csv(\"hdfs://namenode:9000/depi_folder/titanic_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03702739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|survived|count|\n",
      "+--------+-----+\n",
      "|       1|  342|\n",
      "|       0|  549|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "842651ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       S|  644|\n",
      "|       C|  168|\n",
      "|       Q|   77|\n",
      "|    NULL|    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Embarked\").count().orderBy(\"count\",ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "309f028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|pclass|      survivalRate|\n",
      "+------+------------------+\n",
      "|     1| 62.96296296296296|\n",
      "|     3|24.236252545824847|\n",
      "|     2| 47.28260869565217|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.groupBy(\"pclass\").agg((avg(col(\"Survived\"))*100).alias(\"survivalRate\")\n",
    "                          ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7f5d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------------+\n",
      "|max(Fare)|min(Fare)|       avg(Fare)|\n",
      "+---------+---------+----------------+\n",
      "| 512.3292|      0.0|32.2042079685746|\n",
      "+---------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, min\n",
    "\n",
    "df.select(max(\"Fare\"),min(\"Fare\"),avg(\"Fare\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f140efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|AgeGroup|count|\n",
      "+--------+-----+\n",
      "|   19-35|  535|\n",
      "|     60+|   22|\n",
      "|   36-60|  195|\n",
      "|    0-18|  139|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df= df.withColumn(\"AgeGroup\",\n",
    "                  when(df.Age<=18,\"0-18\")\n",
    "                  .when((df.Age>18)&(df.Age<=35),\"19-35\")\n",
    "                  .when((df.Age > 35) & (df.Age <= 60), \"36-60\")\n",
    "                    .otherwise(\"60+\")\n",
    "                  \n",
    "                  )\n",
    "df.groupBy(\"AgeGroup\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
